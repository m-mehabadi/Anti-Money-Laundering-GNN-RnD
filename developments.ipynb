{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Blogs Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timestamp             0\n",
            "From Bank             0\n",
            "Account               0\n",
            "To Bank               0\n",
            "Account.1             0\n",
            "Amount Received       0\n",
            "Receiving Currency    0\n",
            "Amount Paid           0\n",
            "Payment Currency      0\n",
            "Payment Format        0\n",
            "Is Laundering         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load the CSV file into a pandas dataframe\n",
        "# only load the first 10000 rows\n",
        "df = pd.read_csv(\"./modularity_aware_gae/data/IBM_AML/HI-Small_Trans.csv\")\n",
        "\n",
        "# Check for null values\n",
        "null_values = df.isnull().sum()\n",
        "print(null_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a mapping from account IDs to integers\n",
        "account_to_int = {account: idx for idx, account in enumerate(set(df['Account']).union(set(df['Account.1'])))}\n",
        "int_to_account = {idx: account for account, idx in account_to_int.items()}\n",
        "df2 = df.copy()\n",
        "df2['Account'] = df2['Account'].map(account_to_int)\n",
        "df2['Account.1'] = df2['Account.1'].map(account_to_int)\n",
        "\n",
        "# Create a new graph with integer node labels\n",
        "G2 = nx.from_pandas_edgelist(df2, source='Account', target='Account.1', edge_attr='Amount Paid', create_using=nx.Graph())\n",
        "\n",
        "# save the graph G to a file without edge attributes (Amount Paid)\n",
        "nx.write_edgelist(G2, \"./modularity_aware_gae/data/IBM_AML/IBM.edgelist\", data=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# working out the label set from the IBM df\n",
        "# we will consider a list of False with size of the number of unique values in the union of the two columns\n",
        "# we will first consider all the accounts that have atleast one transaction with Is Laundering = 1\n",
        "# let's set the value of the list to True for these accounts each number should\n",
        "# correspond to the index of the account in the account_to_int dictionary\n",
        "# we will then save this list to a file\n",
        "\n",
        "# Create a list of False values with the size of the number of unique accounts\n",
        "labels = [False] * len(account_to_int)\n",
        "\n",
        "# Find accounts with at least one laundering transaction\n",
        "laundering_accounts = set(df2[df2['Is Laundering'] == 1]['Account'])\n",
        "laundering_accounts = laundering_accounts.union(set(df2[df2['Is Laundering'] == 1]['Account.1']))\n",
        "\n",
        "# Set the label to True for accounts with laundering transactions\n",
        "for account in laundering_accounts:\n",
        "    labels[account] = True\n",
        "\n",
        "# Save the labels to a file\n",
        "with open(\"./modularity_aware_gae/data/IBM_AML/IBM-labels.csv\", 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write(f\"{str(label)}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2341772151898733% of the accounts are labeled as laundering\n"
          ]
        }
      ],
      "source": [
        "print(f\"{sum(labels)/len(labels) * 100}% of the accounts are labeled as laundering\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Moher\\Personal\\PhD\\Projects\\AML GNN\\modularity_aware_gae\\modularity_aware_gae\n",
            "\n",
            " \n",
            " \n",
            " \n",
            "[MODULARITY-AWARE GRAPH AUTOENCODERS]\n",
            " \n",
            " \n",
            " \n",
            "\n",
            "EXPERIMENTAL SETTING \n",
            "\n",
            "- Graph dataset: None\n",
            "- Mode name: gcn_vae\n",
            "- Number of models to train: 1\n",
            "- Number of training iterations for each model: 200\n",
            "- Learning rate: 0.01\n",
            "- Dropout rate: 0.0\n",
            "- Use of node features in the input layer: False\n",
            "- Dimension of the GCN hidden layer: 32\n",
            "- Dimension of the output layer: 16\n",
            "- lambda: 0.5\n",
            "- beta: 0.75\n",
            "- gamma: 2.0\n",
            "- s: 10\n",
            "- FastGAE: no \n",
            "\n",
            "Final embedding vectors will be evaluated on:\n",
            "- Task 2, i.e., joint community detection and link prediction\n",
            "\n",
            " \n",
            " \n",
            " \n",
            "\n",
            "Using custom dataset from: ../data/IBM_AML/IBM.edgelist\n",
            "Using custom labels from: ../data/IBM_AML/IBM-labels.csv\n",
            "LOADING DATA\n",
            "\n",
            "Loading custom dataset\n",
            "- Number of nodes: 515080\n",
            "- Number of communities: 2\n",
            "- Use of node features: False\n",
            "Done! \n",
            " \n",
            " \n",
            " \n",
            "\n",
            "EXPERIMENTS ON MODEL 1 / 1 \n",
            "\n",
            "STEP 1/3 - PREPROCESSING STEPS \n",
            "\n",
            "Masking some edges from the training graph, for link prediction\n",
            "(validation set: 5.0 % of edges - test set: 10.0 % of edges)\n",
            "c:\\Users\\Moher\\Personal\\PhD\\Projects\\AML GNN\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-05 22:45:42.232130: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_100.dll'; dlerror: cudart64_100.dll not found\n",
            "2025-03-05 22:45:42.232406: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 137, in <module>\n",
            "    mask_test_edges(adj_init, FLAGS.prop_test, FLAGS.prop_val)\n",
            "  File \"c:\\Users\\Moher\\Personal\\PhD\\Projects\\AML GNN\\_pyenv\\lib\\site-packages\\modularity_aware_gae\\preprocessing.py\", line 79, in mask_test_edges\n",
            "    assert np.diag(adj.todense()).sum() == 0\n",
            "  File \"c:\\Users\\Moher\\Personal\\PhD\\Projects\\AML GNN\\_pyenv\\lib\\site-packages\\scipy\\sparse\\base.py\", line 851, in todense\n",
            "    return asmatrix(self.toarray(order=order, out=out))\n",
            "  File \"c:\\Users\\Moher\\Personal\\PhD\\Projects\\AML GNN\\_pyenv\\lib\\site-packages\\scipy\\sparse\\compressed.py\", line 1025, in toarray\n",
            "    out = self._process_toarray_args(order, out)\n",
            "  File \"c:\\Users\\Moher\\Personal\\PhD\\Projects\\AML GNN\\_pyenv\\lib\\site-packages\\scipy\\sparse\\base.py\", line 1189, in _process_toarray_args\n",
            "    return np.zeros(self.shape, dtype=self.dtype, order=order)\n",
            "numpy.core._exceptions.MemoryError: Unable to allocate 988. GiB for an array with shape (515080, 515080) and data type int32\n"
          ]
        }
      ],
      "source": [
        "%pwd\n",
        "%cd modularity_aware_gae/modularity_aware_gae\n",
        "!python train.py --dataset_path=../data/IBM_AML/IBM.edgelist --labelset_path=../data/IBM_AML/IBM-labels.csv --features=False --task=task_2 --model=gcn_vae --iterations=200 --learning_rate=0.01 --hidden=32 --dimension=16 --beta=0.75 --lamb=0.5 --gamma=2 --s_reg=10 --fastgae=False --nb_run=1\n",
        "%cd ../.."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "_pyenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
